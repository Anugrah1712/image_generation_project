import os
import base64
from io import BytesIO
from dotenv import load_dotenv
from PIL import Image
import cv2
import gdown
from insightface.app import FaceAnalysis
from insightface.model_zoo import get_model
from gfpgan import GFPGANer
import google.genai as genai
from google.genai import types

# --------------------------
# 0. Setup directories
# --------------------------
output_dir = "outputs"
os.makedirs(output_dir, exist_ok=True)
weights_dir = "weights"
os.makedirs(weights_dir, exist_ok=True)
print("‚úÖ Directories created/verified.")

# --------------------------
# 1. Load environment variables & Gemini client
# --------------------------
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    raise ValueError("‚ùå GEMINI_API_KEY not found. Add it to your .env file")
print("‚úÖ Gemini API key loaded.")
client = genai.Client(api_key=api_key)

# --------------------------
# 2. Helper function
# --------------------------
def encode_image(path):
    print(f"üîπ Encoding image: {path}")
    with open(path, "rb") as f:
        return base64.b64encode(f.read()).decode("utf-8")


# --------------------------
# 3. Refine prompt using Gemini
# --------------------------
def refine_prompt(original_prompt):
    print("ü™Ñ Refining prompt using Gemini...")
    system_instruction = (
        "You are an expert at crafting detailed, visually rich prompts for AI image generation. "
        "Carefully understand the user's intent and refine their prompt by enhancing composition, lighting, realism, and detail, "
        "while preserving the original meaning. Avoid unnecessary exaggeration or stylistic deviation. "
        "If the user mentions input image, source image, or target image in their prompt, never modify or replace these images "
        "unless the user explicitly instructs to make changes to them."
    )


    response = client.models.generate_content(
        model="gemini-2.0-flash",
        contents=[
            types.Content(
                parts=[
                    types.Part(text=system_instruction),
                    types.Part(text=f"User prompt: {original_prompt}")
                ]
            )
        ]
    )

    refined = None
    for candidate in response.candidates:
        for part in candidate.content.parts:
            if part.text:
                refined = part.text.strip()
                break

    if not refined:
        print("‚ö†Ô∏è Prompt refinement failed. Using original prompt.")
        return original_prompt

    print(f"‚ú® Refined Prompt:\n{refined}\n")
    return refined


# --------------------------
# 4. Generate image with Gemini
# --------------------------
def generate_gemini_image(prompt, img1_path=None, img2_path=None):
    model_name = "gemini-2.0-flash-preview-image-generation"
    print(f"üî∏ Using Gemini model: {model_name}")

    refined_prompt = refine_prompt(prompt)
    parts = [types.Part(text=refined_prompt)]

    if img1_path:
        parts.append(types.Part(inline_data=types.Blob(mime_type="image/jpeg", data=encode_image(img1_path))))
    if img2_path:
        parts.append(types.Part(inline_data=types.Blob(mime_type="image/jpeg", data=encode_image(img2_path))))

    contents = [types.Content(parts=parts)]
    response = client.models.generate_content(
        model=model_name,
        contents=contents,
        config=types.GenerateContentConfig(response_modalities=["TEXT", "IMAGE"]),
    )

    for candidate in response.candidates:
        for part in candidate.content.parts:
            if part.inline_data is not None:
                image = Image.open(BytesIO(part.inline_data.data))
                out_path = os.path.join(output_dir, "gen_img_using_gemini.png")
                image.save(out_path)
                print(f"‚úÖ Generated image saved at {out_path}")
                return out_path

    raise RuntimeError("‚ùå No image was generated by Gemini!")


# --------------------------
# 5. Download weights if missing
# --------------------------
inswapper_path = os.path.join(weights_dir, "inswapper_128.onnx")
gfpgang_path = os.path.join(weights_dir, "GFPGANv1.4.pth")

if not os.path.exists(inswapper_path):
    print("‚¨áÔ∏è Downloading InsightFace inswapper weights...")
    gdown.download("https://drive.google.com/uc?id=1krOLgjW2tAPaqV-Bw4YALz0xT5zlb5HF", inswapper_path, quiet=False)
if not os.path.exists(gfpgang_path):
    print("‚¨áÔ∏è Downloading GFPGAN weights...")
    gdown.download("https://github.com/TencentARC/GFPGAN/releases/download/v1.3.4/GFPGANv1.4.pth", gfpgang_path, quiet=False)
print("‚úÖ All model weights verified.")


# --------------------------
# 6. Initialize InsightFace
# --------------------------
try:
    import tensorflow as tf
    ctx_id = 0
    print("‚úÖ GPU detected. Using GPU for InsightFace.")
except Exception:
    ctx_id = -1
    print("‚ö†Ô∏è GPU not detected. Using CPU for InsightFace.")

app = FaceAnalysis(name='buffalo_l')
app.prepare(ctx_id=ctx_id, det_thresh=0.3, det_size=(640, 640))  # Lower threshold improves detection
swapper = get_model(inswapper_path, download=False, download_zip=False)
print("‚úÖ InsightFace models initialized.")


# --------------------------
# 7. Face Swap Function (with auto-retry + better handling)
# --------------------------
def insightface_swap(source_path, target_path, output_path):
    print(f"üîπ Starting face swap: source={source_path}, target={target_path}")

    source_img = cv2.imread(source_path)
    target_img = cv2.imread(target_path)

    # Resize to ensure faces are large enough for detection
    source_img = cv2.resize(source_img, (800, 800))
    target_img = cv2.resize(target_img, (800, 800))

    source_faces = app.get(source_img)
    target_faces = app.get(target_img)
    print(f"üîç Found {len(source_faces)} source face(s), {len(target_faces)} target face(s)")

    # Try reversing source/target if detection fails
    if not source_faces or not target_faces:
        print("‚ö†Ô∏è No face detected in one of the images. Trying reversed input...")
        source_faces, target_faces = target_faces, source_faces
        if not source_faces or not target_faces:
            return None, "‚ùå No face detected in either image (even after retry)."

    try:
        result = swapper.get(target_img, target_faces[0], source_faces[0], paste_back=True)
        cv2.imwrite(output_path, result)
        print(f"‚úÖ Face swapped successfully: {output_path}")
        return output_path, None
    except Exception as e:
        return None, f"‚ùå Face swap failed: {e}"


# --------------------------
# 8. Full Pipeline (Gemini + Swap)
# --------------------------
def process_images(prompt, img1_path=None, img2_path=None, face_swap=False):
    print("üöÄ Starting full image processing pipeline...")

    if face_swap:
        print("üé≠ Face Swap mode enabled ‚Äî skipping Gemini image generation.")

        if not img1_path or not img2_path:
            raise ValueError("‚ùå Face swap mode requires two images!")

        swapped_path = os.path.join(output_dir, "result_swap.jpg")
        swapped_result, error = insightface_swap(img1_path, img2_path, swapped_path)

        if error:
            print(error)
            raise ValueError(error)

        print("üîπ Enhancing swapped result using GFPGAN (Real-ESRGAN removed)...")
        img = cv2.imread(swapped_result)

        gfpganer = GFPGANer(
            model_path=gfpgang_path,
            upscale=1,
            arch="clean",
            channel_multiplier=2,
            bg_upsampler=None
        )
        _, _, restored = gfpganer.enhance(img, has_aligned=False, only_center_face=False, paste_back=True)

        final_path = os.path.join(output_dir, "swapped_final.jpg")
        cv2.imwrite(final_path, restored)
        print(f"‚úÖ Final image (GFPGAN only) saved: {final_path}")

        return final_path

    else:
        print("ü™Ñ Using Gemini to generate/edit image...")
        return generate_gemini_image(prompt, img1_path, img2_path)
